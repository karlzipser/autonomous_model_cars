# Autonomous Model Cars

<img src="https://github.com/karlzipser/autonomous_model_cars/blob/master/imgs/indoor_arena-320x180.gif">

<img src="https://github.com/karlzipser/autonomous_model_cars/blob/master/imgs/outdoor_arena_4-320x180.gif">

<img src="https://github.com/karlzipser/autonomous_model_cars/blob/master/imgs/navigating-320x180.gif">

These are examples of projects my team and I created for the Berkeley Deep Drive program.


  body { font-family:Calibri; font-size:12pt } p { margin:0pt } li { margin-top:0pt; margin-bottom:0pt }

**Publications**:

• **Autonomous-Driving Related, Peer-Reviewed**

**•**      [**Xia, Y., Kim, J., Canny, J., Zipser, K., Canas-Bajo, T., & Whitney, D. (2020). Periphery-fovea multi-resolution driving model guided by human attention. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 1767-1775).**](https://openaccess.thecvf.com/content_WACV_2020/html/Xia_Periphery-Fovea_Multi-Resolution_Driving_Model_Guided_by_Human_Attention_WACV_2020_paper.html) 

**•**      [**Xia, Y., Manassi, M., Nakayama, K., Zipser, K., & Whitney, D. (2020). Visual crowding in driving. Journal of vision, 20(6), 1-1.**](https://jov.arvojournals.org/article.aspx?articleid=2766295)

**•**      [**Chowdhuri, S., Pankaj, T., & Zipser, K. (2019, January). Multinet: Multi-modal multi-task learning for autonomous driving. In 2019 IEEE Winter Conference on Applications of Computer Vision (WACV) (pp. 1496-1504). IEEE.**](https://ieeexplore.ieee.org/abstract/document/8658798)

**•**      [**Yellapragada, B., Anderson, A., Yu, S., & Zipser, K. (2018). Motion Selectivity of Neurons in Self-Driving Networks. In Proceedings of the European Conference on Computer Vision (ECCV) Workshops.**](https://openaccess.thecvf.com/content_eccv_2018_workshops/w28/html/Yellapragada_Motion_Selectivity_of_Neurons_in_Self-Driving_Networks_ECCVW_2018_paper.html)

**•**      [**Hornauer, S., Zipser, K., & Yu, S. (2018). Imitation learning of path-planned driving using disparity-depth images. In Proceedings of the European Conference on Computer Vision (ECCV) Workshops.**](https://openaccess.thecvf.com/content_ECCVW_2018/papers/11133/Hornauer_Imitation_Learning_of_Path-Planned_Driving_using_Disparity-Depth_Images_ECCVW_2018_paper.pdf)

**•**      [**Xia, Y., Zhang, D., Kim, J., Nakayama, K., Zipser, K., & Whitney, D. (2018, December). Predicting driver attention in critical situations. In Asian conference on computer vision (pp. 658-674). Springer, Cham.**](https://link.springer.com/chapter/10.1007/978-3-030-20873-8_42)

**• Autonomous Driving Related, Non Peer-Reviewed**

**•**      [**Xia, Y., Zhang, D., Pozdnoukhov, A., Nakayama, K., Zipser, K., & Whitney, D. (2017). Training a network to attend like human drivers saves it from common but misleading loss functions. arXiv preprint arXiv:1711.06406.**](https://escholarship.org/content/qt0vx1h4j4/qt0vx1h4j4_noSplash_c42450314ed793f9fa52312b29dba85b.pdf)

**•**      [**Hornauer, S., Zipser, K., & Yu, S. X. (2017). Learning to Roam Free from Small-Space Autonomous Driving with A Path Planner. arXiv preprint arXiv:1709.10512.**](https://arxiv.org/abs/1709.10512)

**•**      [**Hou, Y., Hornauer, S., & Zipser, K. (2017). Fast recurrent fully convolutional networks for direct perception in autonomous driving. arXiv preprint arXiv:1711.06459.**](https://arxiv.org/abs/1711.06459)

[Converted to HTML with WordToHTML.net](https://wordtohtml.net)
