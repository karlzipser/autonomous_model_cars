# Autonomous Model Cars

<img src="https://github.com/karlzipser/autonomous_model_cars/blob/master/imgs/indoor_arena-320x180.gif">

<img src="https://github.com/karlzipser/autonomous_model_cars/blob/master/imgs/outdoor_arena_4-320x180.gif">

<img src="https://github.com/karlzipser/autonomous_model_cars/blob/master/imgs/navigating-320x180.gif">

These are examples of projects my team and I created for the Berkeley Deep Drive program.


			<p style="widows:0; orphans:0; font-size:11pt">
				<strong><span style="font-family:Helvetica-Bold; ">Publications</span></strong><span style="font-family:Helvetica">:</span>
			</p>
			<p style="widows:0; orphans:0; font-size:11pt">
				<span style="font-family:Helvetica">&#xa0;</span>
			</p>
			<p style="text-indent:18pt; widows:0; orphans:0; font-size:11pt">
				<span style="font-family:Helvetica">• </span><strong><span style="font-family:Helvetica-Bold; ">Autonomous-Driving Related, Peer-Reviewed</span></strong>
			</p>
			<p style="widows:0; orphans:0; font-size:11pt">
				<span style="font-family:Helvetica">&#xa0;</span>
			</p>
			<p style="margin-left:86.65pt; text-indent:-49.35pt; text-align:justify; line-height:120%; widows:0; orphans:0; font-size:10.5pt">
				<strong><span style="font-family:Helvetica-Bold; font-size:9pt; color:#103cc0"><span style="font-weight:normal">•</span></strong></span><span style="width:8.85pt; font:7pt 'Times New Roman'; display:inline-block">&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; </span><a href="https://openaccess.thecvf.com/content_WACV_2020/html/Xia_Periphery-Fovea_Multi-Resolution_Driving_Model_Guided_by_Human_Attention_WACV_2020_paper.html" style="text-decoration:none"><strong><span style="line-height:120%; font-family:Helvetica-Bold; font-size:9pt; color:#0c61ab">Xia, Y., Kim, J., Canny, J., Zipser, K., Canas-Bajo, T., &amp; Whitney, D. (2020). Periphery-fovea multi-resolution driving model guided by human attention. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 1767-1775).</span></strong><strong><span style="line-height:120%; font-family:Helvetica-Bold; font-size:9pt; color:#0c61ab">&#xa0;</span></strong></a>
			</p>
			<p style="margin-left:86.65pt; text-indent:-49.35pt; text-align:justify; line-height:120%; widows:0; orphans:0; font-size:10.5pt">
				<strong><span style="font-family:Helvetica-Bold; font-size:9pt; color:#103cc0"><span style="font-weight:normal">•</span></strong></span><span style="width:8.85pt; font:7pt 'Times New Roman'; display:inline-block">&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; </span><a href="https://jov.arvojournals.org/article.aspx?articleid=2766295" style="text-decoration:none"><strong><span style="line-height:120%; font-family:Helvetica-Bold; font-size:9pt; color:#0c61ab">Xia, Y., Manassi, M., Nakayama, K., Zipser, K., &amp; Whitney, D. (2020). Visual crowding in driving. Journal of vision, 20(6), 1-1.</span></strong></a>
			</p>
			<p style="margin-left:86.65pt; text-indent:-49.35pt; text-align:justify; line-height:120%; widows:0; orphans:0; font-size:10.5pt">
				<strong><span style="font-family:Helvetica-Bold; font-size:9pt; color:#103cc0"><span style="font-weight:normal">•</span></strong></span><span style="width:8.85pt; font:7pt 'Times New Roman'; display:inline-block">&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; </span><a href="https://ieeexplore.ieee.org/abstract/document/8658798" style="text-decoration:none"><strong><span style="line-height:120%; font-family:Helvetica-Bold; font-size:9pt; color:#0c61ab">Chowdhuri, S., Pankaj, T., &amp; Zipser, K. (2019, January). Multinet: Multi-modal multi-task learning for autonomous driving. In 2019 IEEE Winter Conference on Applications of Computer Vision (WACV) (pp. 1496-1504). IEEE.</span></strong></a>
			</p>
			<p style="margin-left:86.65pt; text-indent:-49.35pt; text-align:justify; line-height:120%; widows:0; orphans:0; font-size:10.5pt">
				<strong><span style="font-family:Helvetica-Bold; font-size:9pt; color:#103cc0"><span style="font-weight:normal">•</span></strong></span><span style="width:8.85pt; font:7pt 'Times New Roman'; display:inline-block">&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; </span><a href="https://openaccess.thecvf.com/content_eccv_2018_workshops/w28/html/Yellapragada_Motion_Selectivity_of_Neurons_in_Self-Driving_Networks_ECCVW_2018_paper.html" style="text-decoration:none"><strong><span style="line-height:120%; font-family:Helvetica-Bold; font-size:9pt; color:#0c61ab">Yellapragada, B., Anderson, A., Yu, S., &amp; Zipser, K. (2018). Motion Selectivity of Neurons in Self-Driving Networks. In Proceedings of the European Conference on Computer Vision (ECCV) Workshops.</span></strong></a>
			</p>
			<p style="margin-left:86.65pt; text-indent:-49.35pt; text-align:justify; line-height:120%; widows:0; orphans:0; font-size:10.5pt">
				<strong><span style="font-family:Helvetica-Bold; font-size:9pt; color:#103cc0"><span style="font-weight:normal">•</span></strong></span><span style="width:8.85pt; font:7pt 'Times New Roman'; display:inline-block">&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; </span><a href="https://openaccess.thecvf.com/content_ECCVW_2018/papers/11133/Hornauer_Imitation_Learning_of_Path-Planned_Driving_using_Disparity-Depth_Images_ECCVW_2018_paper.pdf" style="text-decoration:none"><strong><span style="line-height:120%; font-family:Helvetica-Bold; font-size:9pt; color:#0c61ab">Hornauer, S., Zipser, K., &amp; Yu, S. (2018). Imitation learning of path-planned driving using disparity-depth images. In Proceedings of the European Conference on Computer Vision (ECCV) Workshops.</span></strong></a>
			</p>
			<p style="margin-left:74.65pt; text-indent:-37.35pt; text-align:justify; line-height:120%; widows:0; orphans:0; font-size:9pt">
				<strong><span style="font-family:Helvetica-Bold; color:#103cc0">&#xa0;</span></strong>
			</p>
			<p style="margin-left:86.65pt; text-indent:-49.35pt; text-align:justify; line-height:120%; widows:0; orphans:0; font-size:10.5pt">
				<strong><span style="font-family:Helvetica-Bold; font-size:9pt; color:#103cc0"><span style="font-weight:normal">•</span></strong></span><span style="width:8.85pt; font:7pt 'Times New Roman'; display:inline-block">&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; </span><a href="https://link.springer.com/chapter/10.1007/978-3-030-20873-8_42" style="text-decoration:none"><strong><span style="line-height:120%; font-family:Helvetica-Bold; font-size:9pt; color:#0c61ab">Xia, Y., Zhang, D., Kim, J., Nakayama, K., Zipser, K., &amp; Whitney, D. (2018, December). Predicting driver attention in critical situations. In Asian conference on computer vision (pp. 658-674). Springer, Cham.</span></strong></a>
			</p>
			<p style="margin-left:74.65pt; text-indent:-37.35pt; text-align:justify; line-height:120%; widows:0; orphans:0; font-size:11pt">
				<strong><span style="font-family:Helvetica-Bold; color:#103cc0">&#xa0;</span></strong>
			</p>
			<p style="margin-left:74.65pt; text-indent:-37.35pt; text-align:justify; line-height:120%; widows:0; orphans:0; font-size:11pt">
				<strong><span style="font-family:Helvetica-Bold; color:#103cc0">&#xa0;</span></strong>
			</p>
			<p style="margin-left:18pt; text-align:justify; widows:0; orphans:0; font-size:11pt">
				<strong><span style="font-family:Helvetica-Bold; ">• Autonomous Driving Related, Non Peer-Reviewed</span></strong>
			</p>
			<p style="widows:0; orphans:0; font-size:11pt">
				<span style="font-family:Helvetica">&#xa0;</span>
			</p>
			<p style="margin-left:86.65pt; text-indent:-49.35pt; text-align:justify; line-height:120%; widows:0; orphans:0; font-size:10.5pt">
				<strong><span style="font-family:Helvetica-Bold; font-size:9pt; color:#103cc0"><span style="font-weight:normal">•</span></strong></span><span style="width:8.85pt; font:7pt 'Times New Roman'; display:inline-block">&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; </span><a href="https://escholarship.org/content/qt0vx1h4j4/qt0vx1h4j4_noSplash_c42450314ed793f9fa52312b29dba85b.pdf" style="text-decoration:none"><strong><span style="line-height:120%; font-family:Helvetica-Bold; font-size:9pt; color:#0c61ab">Xia, Y., Zhang, D., Pozdnoukhov, A., Nakayama, K., Zipser, K., &amp; Whitney, D. (2017). Training a network to attend like human drivers saves it from common but misleading loss functions. arXiv preprint arXiv:1711.06406.</span></strong></a>
			</p>
			<p style="margin-left:86.65pt; text-indent:-49.35pt; text-align:justify; line-height:120%; widows:0; orphans:0; font-size:10.5pt">
				<strong><span style="font-family:Helvetica-Bold; font-size:9pt; color:#103cc0"><span style="font-weight:normal">•</span></strong></span><span style="width:8.85pt; font:7pt 'Times New Roman'; display:inline-block">&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; </span><a href="https://arxiv.org/abs/1709.10512" style="text-decoration:none"><strong><span style="line-height:120%; font-family:Helvetica-Bold; font-size:9pt; color:#0c61ab">Hornauer, S., Zipser, K., &amp; Yu, S. X. (2017). Learning to Roam Free from Small-Space Autonomous Driving with A Path Planner. arXiv preprint arXiv:1709.10512.</span></strong></a>
			</p>
			<p style="margin-left:86.65pt; text-indent:-49.35pt; text-align:justify; line-height:120%; widows:0; orphans:0; font-size:10.5pt">
				<strong><span style="font-family:Helvetica-Bold; color:#103cc0"><span style="font-weight:normal">•</span></strong></span><span style="width:8.32pt; font:7pt 'Times New Roman'; display:inline-block">&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; </span><a href="https://arxiv.org/abs/1711.06459" style="text-decoration:none"><strong><span style="line-height:120%; font-family:Helvetica-Bold; font-size:9pt; color:#0c61ab">Hou, Y., Hornauer, S., &amp; Zipser, K. (2017). Fast recurrent fully convolutional networks for direct perception in autonomous driving. arXiv preprint arXiv:1711.06459.</span></strong></a>
			</p>
